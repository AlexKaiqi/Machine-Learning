{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rnn_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 循环神经网络的前向传播\n",
    " 我们来看一下下面的循环神经网络的图，在这里使用的是$T_x = T_y$，我们来实现它。\n",
    " \n",
    "![](https://img-blog.csdn.net/20180702215837813?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM3MzMzMjY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "**图 1**: 基本的RNN模型\n",
    "</p>\n",
    "\n",
    "我们怎么才能实现它呢？有以下步骤：\n",
    "1. 实现RNN的一个时间步所需要计算的东西。\n",
    "2.在$Tx$时间步上实现一个循环，以便一次处理所有输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 - RNN单元\n",
    " 循环神经网络可以看作是单元的重复，首先要实现单个时间步的计算，下图描述了RNN单元的单个时间步的操作。\n",
    "![RNN single step](./images/RNN-single-step.png)\n",
    "<p style=\"text-align:center\">\n",
    "**图 2**: 基本的RNN单元.\n",
    "</p>\n",
    "输入 $x^{\\langle t \\rangle}$ (当前输入) 与 $a^{\\langle t - 1\\rangle}$ (包含过去信息的上一隐藏层的激活值), 输出 $a^{\\langle t \\rangle}$ 给下一个RNN单元，也用于预测 $y^{\\langle t \\rangle}$\n",
    " 现在我们要根据图2来实现一个RNN单元，这需要由以下几步完成：\n",
    "\n",
    "使用tanh函数计算隐藏单元的激活值：$a^{<t>}=tanh(W_{aa}a^{<t−1>}+Waxx⟨t⟩+ba) a^{\\langle t \\rangle} = \\tanh(W_{aa}a^{\\langle t - 1 \\rangle} + W_{ax}x^{\\langle t \\rangle} + b_a)a \n",
    "⟨t⟩=tanh(W_{aa}a^<t-1> \n",
    "⟨t−1⟩\n",
    " +W \n",
    "ax\n",
    "​\t\n",
    " x \n",
    "⟨t⟩\n",
    " +b \n",
    "a\n",
    "​\t\n",
    " )\n",
    "\n",
    "使用a⟨t⟩ a^{\\langle t \\rangle}a \n",
    "⟨t⟩\n",
    " 计算yˆ⟨t⟩=softmax(Wyaa⟨t⟩+by) \\hat y ^{\\langle t \\rangle} = softmax( W_{ya}a^{\\langle t \\rangle} + b_y ) \n",
    "y\n",
    "^\n",
    "​\t\n",
    "  \n",
    "⟨t⟩\n",
    " =softmax(W \n",
    "ya\n",
    "​\t\n",
    " a \n",
    "⟨t⟩\n",
    " +b \n",
    "y\n",
    "​\t\n",
    " )，softmax在rnn_utils内。\n",
    "\n",
    "把(a⟨t⟩,a⟨t⟩−1,x⟨t⟩,parameters) ( a^{\\langle t \\rangle},a^{\\langle t \\rangle - 1},x^{\\langle t \\rangle},parameters)(a \n",
    "⟨t⟩\n",
    " ,a \n",
    "⟨t⟩−1\n",
    " ,x \n",
    "⟨t⟩\n",
    " ,parameters)存储到cache中。\n",
    "\n",
    "返回a⟨t⟩,y⟨t⟩ a^{\\langle t \\rangle},y^{\\langle t \\rangle}a \n",
    "⟨t⟩\n",
    " ,y \n",
    "⟨t⟩\n",
    " 与cache。\n",
    "\n",
    " 我们将向量化m mm个样本，因此，x⟨t⟩ x^{\\langle t \\rangle}x \n",
    "⟨t⟩\n",
    " 的维度为(nx,m) (n_x,m)(n \n",
    "x\n",
    "​\t\n",
    " ,m)，a⟨t⟩ a^{\\langle t \\rangle}a \n",
    "⟨t⟩\n",
    " 的维度为(na,m) (n_a,m)(n \n",
    "a\n",
    "​\t\n",
    " ,m)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_cell_forward(xt, a_prev, parameters):\n",
    "    \"\"\"\n",
    "    根据图2实现RNN单元的单步前向传播\n",
    "    \n",
    "    参数：\n",
    "        xt -- 时间步“t”输入的数据，维度为（n_x, m）\n",
    "        a_prev -- 时间步“t - 1”的隐藏隐藏状态，维度为（n_a, m）\n",
    "        parameters -- 字典，包含了以下内容:\n",
    "                        Wax -- 矩阵，输入乘以权重，维度为（n_a, n_x）\n",
    "                        Waa -- 矩阵，隐藏状态乘以权重，维度为（n_a, n_a）\n",
    "                        Wya -- 矩阵，隐藏状态与输出相关的权重矩阵，维度为（n_y, n_a）\n",
    "                        ba  -- 偏置，维度为（n_a, 1）\n",
    "                        by  -- 偏置，隐藏状态与输出相关的偏置，维度为（n_y, 1）\n",
    "    \n",
    "    返回：\n",
    "        a_next -- 下一个隐藏状态，维度为（n_a， m）\n",
    "        yt_pred -- 在时间步“t”的预测，维度为（n_y， m）\n",
    "        cache -- 反向传播需要的元组，包含了(a_next, a_prev, xt, parameters)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 从“parameters”获取参数\n",
    "    Wax = parameters[\"Wax\"]\n",
    "    Waa = parameters[\"Waa\"]\n",
    "    Wya = parameters[\"Wya\"]\n",
    "    ba = parameters[\"ba\"]\n",
    "    by = parameters[\"by\"]\n",
    "    \n",
    "    # 使用上面的公式计算下一个激活值\n",
    "    a_next = np.tanh(np.dot(Waa, a_prev) + np.dot(Wax, xt) + ba)\n",
    "    \n",
    "    # 使用上面的公式计算当前单元的输出\n",
    "    yt_pred = rnn_utils.softmax(np.dot(Wya, a_next) + by)\n",
    "    \n",
    "    # 保存反向传播需要的值\n",
    "    cache = (a_next, a_prev, xt, parameters)\n",
    "    \n",
    "    return a_next, yt_pred, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_next[4] =  [ 0.59584544  0.18141802  0.61311866  0.99808218  0.85016201  0.99980978\n",
      " -0.18887155  0.99815551  0.6531151   0.82872037]\n",
      "a_next.shape =  (5, 10)\n",
      "yt_pred[1] = [0.9888161  0.01682021 0.21140899 0.36817467 0.98988387 0.88945212\n",
      " 0.36920224 0.9966312  0.9982559  0.17746526]\n",
      "yt_pred.shape =  (2, 10)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "xt = np.random.randn(3,10)\n",
    "a_prev = np.random.randn(5,10)\n",
    "Waa = np.random.randn(5,5)\n",
    "Wax = np.random.randn(5,3)\n",
    "Wya = np.random.randn(2,5)\n",
    "ba = np.random.randn(5,1)\n",
    "by = np.random.randn(2,1)\n",
    "parameters = {\"Waa\": Waa, \"Wax\": Wax, \"Wya\": Wya, \"ba\": ba, \"by\": by}\n",
    "\n",
    "a_next, yt_pred, cache = rnn_cell_forward(xt, a_prev, parameters)\n",
    "print(\"a_next[4] = \", a_next[4])\n",
    "print(\"a_next.shape = \", a_next.shape)\n",
    "print(\"yt_pred[1] =\", yt_pred[1])\n",
    "print(\"yt_pred.shape = \", yt_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
